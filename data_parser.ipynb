{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "files = os.listdir(data_folder)\n",
    "source_files = [os.path.join(data_folder, file) for file in files if \".en\" in file]\n",
    "target_files = [os.path.join(data_folder, file) for file in files if \".tm\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train.tm', 'data/dev.tm', 'data/test.tm']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocab(filenames):\n",
    "    vocab = set()\n",
    "    no_words = 0\n",
    "    for file in filenames:\n",
    "        content = open(file).read()\n",
    "        sentences = [sentence.split() for sentence in content.split('\\n')]\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word.lower() not in vocab:\n",
    "                    vocab.add(word.lower())\n",
    "                    no_words += 1\n",
    "    vocab = {word: num for num, word in enumerate(vocab)}\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = generate_vocab(source_files)\n",
    "target_vocab = generate_vocab(target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files_to_indices(filename, vocab):\n",
    "    content = open(filename).read()\n",
    "    return [[vocab[word] for word in sentence.split() if word in vocab] for sentence in content.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = parse_files_to_indices(source_files[0], source_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, source_files, target_files):\n",
    "        self.source_vocab = generate_vocab(source_files)\n",
    "        self.target_vocab = generate_vocab(target_files)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
